# TinyMistral Training Configuration
MODEL_NAME: "M4-ai/TinyMistral-6x248M"
DATASET: "ag_news"

# Training parameters
NUM_EPOCHS: 3
BATCH_SIZE: 16
LEARNING_RATE: 0.0005
WEIGHT_DECAY: 0.01
GRADIENT_CLIPPING: 1.0

# Performance optimization
MAX_BATCHES_PER_EPOCH: 50    # Limit batches for faster training
MAX_VAL_BATCHES: 25          # Limit validation batches

# Data parameters
MAX_LENGTH: 128              # Token sequence length
NUM_WORKERS: 0               # Data loader workers

# Model parameters
FREEZE_BASE_MODEL: true      # Only train classification head
DROPOUT: 0.1

# Paths
RESULTS_DIR: "results/tinymistral"
LOG_LEVEL: "INFO"
